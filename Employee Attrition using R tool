Attrtn <- read.csv("F:/Data Science Program/DSP Project/Attrition.csv")
View(Attrtn)
str(Attrtn)
names(Attrtn)
summary(Attrtn)

library(ggplot2)
library(gridExtra)
library(caret)
library(ROCR)

#Check missing or NA values
sum(is.na(Attrtn))

attach(Attrtn)

#Creating new variables basis evaluation 

#Partition for monthly income variable
Attrtn$MIncome_Low<-as.factor(ifelse(Attrtn$MonthlyIncome<=6000,1,0))
Attrtn$MIncome_Medium<-as.factor(ifelse(Attrtn$MonthlyIncome>6000&Attrtn$MonthlyIncome<=12000,1,0))
Attrtn$MIncome_High<-as.factor(ifelse(Attrtn$MonthlyIncome>12000&Attrtn$MonthlyIncome<=20000,1,0))

#Partition for Age
Attrtn$Young<-as.factor(ifelse(Attrtn$Age>=18&Attrtn$Age<=35,1,0))
Attrtn$Intermediate<-as.factor(ifelse(Attrtn$Age>35&Attrtn$Age<=50,1,0))
Attrtn$Old<-as.factor(ifelse(Attrtn$Age>50&Attrtn$Age<=60,1,0))

#Partition for YearsAtCompany
Attrtn$LessYears<-as.factor(ifelse(Attrtn$YearsAtCompany>0&Attrtn$YearsAtCompany<=10,1,0))
Attrtn$ManyYears<-as.factor(ifelse(Attrtn$YearsAtCompany>10&Attrtn$YearsAtCompany<=20,1,0))
Attrtn$Experienced<-as.factor(ifelse(Attrtn$YearsAtCompany>20&Attrtn$YearsAtCompany<=30,1,0))
Attrtn$Veteran<-as.factor(ifelse(Attrtn$YearsAtCompany>30&Attrtn$YearsAtCompany<=40,1,0))

#Partion for YearsSinceLastPromotion
#Attrtn$PromotedEarly<-as.factor(ifelse(Attrtn$YearsSinceLastPromotion>=0&Attrtn$YearsSinceLastPromotion<=5,1,0))
#Attrtn$PromotedMediocre<-as.factor(ifelse(Attrtn$YearsSinceLastPromotion>5&Attrtn$YearsSinceLastPromotion<=10,1,0))
#Attrtn$NotPromoted<-as.factor(ifelse(Attrtn$YearsSinceLastPromotion>10&Attrtn$YearsSinceLastPromotion<=15,1,0))


View(Attrtn)


#Summary of all variables
summary(Attrtn)


#Categorical Variables
#cat_Attrtn = c("Attrition","BusinessTravel","Department","Education","EducationField","EnvironmentSatisfaction","Gender",
#             "JobInvolvement","JobLevel","JobRole","JobSatisfaction","MaritalStatus","Over18","OverTime",
#            "PerformanceRating","RelationshipSatisfaction","StandardHours","StockOptionLevel","WorkLifeBalance")

#Convert categorical variables to factor
#Attrtn[cat_Attrtn] <-  lapply(Attrtn[cat_Attrtn], as.factor)

sum(is.na(Attrtn))

#Eliminate variables with low entropy or single level
#Attrtnfinal <- Attrtn[-c(9,19,22,27)]

#Attrtnfinal <- Attrtn[-c(1,9,19,22,27,32,34)]
Attrtnfinal <- Attrtn[-c(1,9,19,22,27,32)]


View(Attrtnfinal)
str(Attrtnfinal)

#Create Training and Testing data(two methods)

#Train <- createDataPartition(Attrtn$Attrition, p=0.8, list=FALSE)
#Attrtntraining <- Attrtn[ Train,]
#Attrtntesting <- Attrtn [ -Train,]

library(caTools)
split <- sample.split(Attrtnfinal, SplitRatio=0.7)

split

Attrtntraining <- subset(Attrtnfinal, split== "TRUE")
Attrtntesting <- subset(Attrtnfinal, split== "FALSE")

View(Attrtntraining)

#Run glm logistic model on training
#Attrtnlogit <- glm(Attrition~ ., data=Attrtntraining,family ='binomial')
#summary(Attrtnlogit)

#Use Feature Selection method
Attrtnlogit2 <- step(glm(Attrition~ ., data=Attrtntraining,family ='binomial'),direction = 'backward')
summary(Attrtnlogit2)

#ManualCalculation

y<- -3.976e-01+1.332e+00*1
a<-exp(-y)
b<-1+a
c<-1/b
c


# concordance and discordance 
Acc=function(model){
  Data = cbind(model$y, model$fitted.values) 
  ones = Data[Data[,1] == 1,]
  zeros = Data[Data[,1] == 0,]
  conc=matrix(0, dim(zeros)[1], dim(ones)[1])
  disc=matrix(0, dim(zeros)[1], dim(ones)[1])
  ties=matrix(0, dim(zeros)[1], dim(ones)[1])
  for (j in 1:dim(zeros)[1])
  {
    for (i in 1:dim(ones)[1])
    {
      if (ones[i,2]>zeros[j,2])
      {conc[j,i]=1}
      else if (ones[i,2]<zeros[j,2])
      {disc[j,i]=1}
      else if (ones[i,2]==zeros[j,2])
      {ties[j,i]=1}
    }
  }
  Pairs=dim(zeros)[1]*dim(ones)[1]
  PercentConcordance=(sum(conc)/Pairs)*100
  PercentDiscordance=(sum(disc)/Pairs)*100
  PercentTied=(sum(ties)/Pairs)*100
  return(list("Percent Concordance"=PercentConcordance,"Percent Discordance"=PercentDiscordance,"Percent Tied"=PercentTied,"Pairs"=Pairs))
}

Acc(Attrtnlogit2)

##Prediction on Testing
Attrtntesting$probs <-predict(Attrtnlogit2,Attrtntesting,type='response')
View(Attrtntesting)$probs
Attrtntesting$Predict<-as.factor(ifelse(Attrtntesting$probs>0.70,'Yes','No'))
table(Attrtntesting$Predict, Attrtntesting$Attrition,Attrtntesting$Predict)
confusionMatrix(Attrtntesting$Attrition,Attrtntesting$Predict)

#Accuracy 

AttrtnAccuracy <- (267+9)/(267+9+3+35)
AttrtnAccuracy

## ROC Curve
library(ROCR)
## make predictions
predictAttrtnTraining =predict(Attrtnlogit2,Attrtntesting, type="response")
# Prediction function 
ROCRpred = prediction(predictAttrtnTraining, Attrtntesting$Attrition)
# Performance function
ROCRperf = performance(ROCRpred,"tpr","fpr")
# Plot ROC curve 
plot(ROCRperf,colorize=TRUE,print.cutoffs.at=seq(0.1,by=0.1))
library(ROCR)
pred = prediction(Attrtntesting$probs, Attrtntesting$Attrition)
as.numeric(performance(pred, "auc")@y.values)

#Modify the threshold as per requirement

Attrtntesting$probs <-predict(Attrtnlogit2,Attrtntesting,type='response')
Attrtntesting$Predict<-as.factor(ifelse(Attrtntesting$probs>0.30,'Yes','No'))
table(Attrtntesting$Predict, Attrtntesting$Attrition,Attrtntesting$Predict)
confusionMatrix(Attrtntesting$Attrition,Attrtntesting$Predict)

AttrtnAccuracyRev <- (370+21)/(370+21+4+58)
AttrtnAccuracyRev


# Building Model 

library(tree)
tree.data=tree(Attrition~.,data=Attrtntraining)
summary(tree.data)
plot(tree.data)
text(tree.data,pretty=0)
tree.data
tree.pred=predict(tree.data,Attrtntesting,type="class")
table(tree.pred,Attrtntesting$Attrition)
library(caret)
confusionMatrix(tree.pred,Attrtntesting$Attrition)
